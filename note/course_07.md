 **【第7講】微型機器學習簡介** 的內容，這一講主要涵蓋了以下幾個重要的方面：

*   **什麼是微型機器學習 (TinyML)：** 講者介紹了 **TinyML** 的概念，指的是在極度資源受限的硬體上運行機器學習演算法，例如微控制器 (MCU)。

*   **TinyML 與傳統 AI 開發的差異：** 相較於在高性能電腦或伺服器上進行的傳統 AI 開發，TinyML 面臨著**嚴峻的資源限制**，包括計算能力、記憶體和功耗都非常有限。這使得直接將大型複雜的 AI 模型部署到 MCU 上幾乎不可能。

*   **TinyML 的應用情境：** 儘管資源有限，TinyML 仍然有許多潛在的應用，例如**影像分類**（在非常小的解析度下）、**異常偵測**（基於感測器訊號而非影像）、以及其他各種需要**低功耗、小型化、邊緣端智慧**的應用。

*   **TinyML 的挑戰與解決方案：** 由於資源限制，TinyML 的重點在於**模型的小型化和高效部署**。這通常涉及到模型壓縮、量化、剪枝等技術，以及針對特定硬體的優化。講者提到了 **ONNX** 這個通用的 AI 模型框架，以及一些開源的模型壓縮方法，例如 **onc (Open Neural Network Compiler)**，它可以幫助將通用 AI 框架的模型壓縮得更小，以便在資源受限的設備上運行。

*   **TinyML 的硬體平台：** 講者提到了像 **Arm Cortex-M4** 這樣的常見 MCU 核心，以及一些在 TinyML 競賽中表現優異的團隊和他們的硬體。例如，台灣的新唐科技 (Nuvoton) 的 MCU 以及 Skymer 公司使用 onc 進行模型壓縮的方案，在 TinyMLPerf 的競賽中取得了不錯的成績。

*   **TinyML 的開發工具和流程：** 講者將傳統 AI 開發流程（資料收集、標註、模型選擇、訓練、優化、部署）與 TinyML 的開發進行比較。他指出，對於 MCU 工程師來說，直接使用傳統 AI 開發框架可能門檻較高。因此，**更方便、整合性更高的工具平台**對於 TinyML 的發展至關重要。這些工具可以幫助將整個流程整合在一個平台或軟體中，方便使用者操作。

*   **NNoM (Neural Network on Microcontroller) 和 LmP (Learning Model Package)：** 講者提到，TinyML 的一個趨勢是出現了像 **NNoM** 這樣的**直接生成可燒錄程式碼**的平台。使用者在平台上完成模型訓練和優化後，可以直接得到可以在 MCU 上執行的程式碼，而無需在 MCU 上編寫大量程式。

*   **針對時序資料的 TinyML：** 講者也提到了如何使用像 **RNN 或 LSTM** 這樣的模型來分析時序資料（例如感測器資料）。雖然 MCU 的計算能力有限，但對於不太長的序列和相對簡單的模型，仍然可以在 MCU 上進行預測，而不是單純的分類。

*   **模型保護的考量：** 在課程的問答環節，有學員提問在沒有網路的環境下如何保護 TinyML 模型不被使用者複製。講者提到，目前大部分 MCU 都是單向寫入，難以讀回模型。對於更高階的 MCU，通常有**TR (TrustZone)** 等安全機制可以鎖住程式碼。此外，也可以使用專門的加密 IC 來增加保護。但他也坦承，對於有決心的破解者，仍然可能透過逆向工程等方法取得模型，但由於 TinyML 模型通常較小且精度可能不高，被竊取的價值可能有限。

 